# === Backend Environment Variables ===

# OpenAI API Key (if using OpenAI embeddings or LLM)
OPENAI_API_KEY=your-openai-api-key

# Vector database settings
VECTOR_DB_PATH=./vector_store
VECTOR_DB_TYPE=chromadb

# PDF upload path
PDF_UPLOAD_PATH=../data

# Embedding model and provider
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_PROVIDER=openai   # Options: openai, huggingface, ollama, bedrock

# LLM model and server settings
LLM_MODEL=llama3
LLAMA_SERVER_URL=http://localhost:11434
LLM_TEMPERATURE=0.1
MAX_TOKENS=1000

# Chunking and retrieval
CHUNK_SIZE=800
CHUNK_OVERLAP=80
RETRIEVAL_K=5
SIMILARITY_THRESHOLD=0.7

# Server settings
HOST=0.0.0.0
PORT=8000
DEBUG=True

# CORS allowed origins (comma separated)
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Logging
LOG_LEVEL=INFO

# === Frontend Environment Variables ===

# Backend API URL (set to your backend or ngrok URL)
NEXT_PUBLIC_BACKEND_URL=http://localhost:8000
